# -*- coding: utf-8 -*-
"""CNN-FINAL .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nzS_du8ws3uUbyX5y9mKnxEHZItp8iOy

#Milestone-2 Final 


*   **Section 3**

*   Bassam Sobhy Abdaltawab
*   Karim Sabry Ahmed
*   Paula Ashraf Sobhy
"""

# Commented out IPython magic to ensure Python compatibility.
# Use the below code to make sure that you select TensorFlow 2.0 in Colab
try:
#   %tensorflow_version 2.x
except Exception:
  pass

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt 
from sklearn.model_selection import KFold

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras as ks
from sklearn.metrics import confusion_matrix

from sklearn.metrics import plot_confusion_matrix

# Validating the TensorFlow version
print(tf.__version__)

# Load the CIFAR-100 dataset

cifar100 = ks.datasets.cifar100

(training_images, training_labels), (test_images, test_labels) = cifar100.load_data()

# Create class_names list object for mapping labels to names
class_names = ['beaver', 'dolphin', 'otter', 'seal', 'whale', 'aquarium fish', 'flatfish', 'ray', 'shark', 'trout','orchids', 'poppies', 'roses', 
               'sunflowers', 'tulips', 'bottles', 'bowls', 'cans', 'cups', 'plates','apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',
               'clock', 'computer keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe', 'bee', 'beetle', 
               'butterfly', 'caterpillar', 'cockroach', 'bear', 'leopard', 'lion', 'tiger', 'wolf', 'bridge', 'castle', 'house', 'road', 'skyscraper',
               'cloud', 'forest', 'mountain', 'plain', 'sea', 'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', 'fox', 'porcupine', 'possum',
               'raccoon', 'skunk','crab', 'lobster', 'snail', 'spider', 'worm', 'baby', 'boy', 'girl', 'man', 'woman', 'crocodile', 'dinosaur', 'lizard',
               'snake', 'turtle', 'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', 'maple', 'oak', 'palm', 'pine', 'willow', 'bicycle', 'bus', 'motorcycle',
               'pickup truck', 'train', 'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']

#data visualization before normlization
index = 10
plt.figure()
plt.imshow(training_images[index])
plt.colorbar()
plt.show()
print(training_labels[index])

#data notmlization 
mean = np.mean(training_images, axis = (0,1,2,3))
std = np.std(training_images, axis = (0,1,2,3))
training_images = (training_images-mean)/(std+1e-7)
test_images = (test_images-mean)/(std+1e-7)

#data visualization after normlization 
index = 10
plt.figure()
plt.imshow(training_images[index])
plt.colorbar()
plt.show()
print(training_labels[index])

# Model configuration values
batch_size = 64
no_epochs = 300
num_folds = 5   # K in K-Fold cross-validation Method

# Parse numbers as floats
training_images = training_images.astype('float32')
test_images = test_images.astype('float32')

#Normalize the data
training_images = training_images / 255.0

test_images = test_images / 255.0

# directly after normalization we add two empty lists for storing the results of cross validation

# Define per-fold score containers 
acc_per_fold = []
loss_per_fold = []

# We concatenate our 'training' and 'testing' datasets ,Merge inputs and targets, K-Fold Cross validation already makes the split between data
inputs = np.concatenate((training_images, test_images), axis=0)
targets = np.concatenate((training_labels, test_labels), axis=0)

# Define the K-fold Cross Validator
kfold = KFold(n_splits=num_folds, shuffle=True)

# K-fold Cross Validation model evaluation

fold_no = 1
for train, test in kfold.split(inputs, targets):
  
  cnn_model = ks.models.Sequential()

  cnn_model.add(ks.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), name='Convolutional_layer_1A'))
  cnn_model.add(ks.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(30, 30, 64), name='Convolutional_layer_1B'))

  cnn_model.add(ks.layers.MaxPooling2D((2, 2),input_shape=(28,28,64), name='Maxpooling_2D_Layer_1'))

  cnn_model.add(ks.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(13, 13, 64), name='Convolutional_layer_2A'))
  cnn_model.add(ks.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(11, 11, 128), name='Convolutional_layer_2B'))

  cnn_model.add(ks.layers.MaxPooling2D((2, 2),input_shape=(9,9,128), name='Maxpooling_2D_Layer_2'))

  cnn_model.add(ks.layers.Conv2D(256, (3, 3), activation='relu', input_shape=(5, 5, 256), name='Convolutional_layer_3A'))

  cnn_model.add(ks.layers.MaxPooling2D((2, 2),input_shape=(3,3,256), name='Maxpooling_2D_Layer_3'))

  tf.keras.layers.Dropout( rate = 0.2, seed=2 )

  cnn_model.add(ks.layers.Flatten(name='Flatten'))
  
  mean = np.mean(training_images, axis = (0,1,2,3))
  std = np.std(training_images, axis = (0,1,2,3))
  training_images = (training_images-mean)/(std+1e-7)
  test_images = (test_images-mean)/(std+1e-7)
  
  cnn_model.add(ks.layers.Dense(1024, activation='relu', name='Hidden_layer_1'))
  tf.keras.layers.Dropout( rate = 0.2, seed=2 )
  cnn_model.add(ks.layers.Dense(512, activation='relu', name='Hidden_layer_2'))
  tf.keras.layers.Dropout( rate = 0.2, seed=2 )
  cnn_model.add(ks.layers.Dense(256, activation='relu', name='Hidden_layer_3'))
  tf.keras.layers.Dropout( rate = 0.2, seed=2 )
  cnn_model.add(ks.layers.Dense(100, activation='relu', name='Hidden_layer_4'))
  
  
  # Data Normlization 
  mean = np.mean(training_images, axis = (0,1,2,3))
  std = np.std(training_images, axis = (0,1,2,3))
  training_images = (training_images-mean)/(std+1e-7)
  test_images = (test_images-mean)/(std+1e-7)

  cnn_model.add(ks.layers.Dense(100, activation='softmax', name='Output_layer'))

  # Optmization Process
  cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

  # Generate a print
  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')


  history = cnn_model.fit(inputs[train], targets[train],batch_size=batch_size,epochs=no_epochs)

  
  # Generate generalization metrics
  scores = cnn_model.evaluate(inputs[test], targets[test])
  print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')
  acc_per_fold.append(scores[1] * 100)
  loss_per_fold.append(scores[0])

  # Increase fold number
  fold_no = fold_no + 1

# == Provide average scores ==
print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
  print('------------------------------------------------------------------------')
  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')
  print('------------------------------------------------------------------------')
  print('Average scores for all folds:')
  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
  print(f'> Loss: {np.mean(loss_per_fold)}')
  print('------------------------------------------------------------------------')

plt.plot(history.history['accuracy'], label='accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

#data visualization after normlization and training
index = 10
plt.figure()
plt.imshow(training_images[index])
plt.colorbar()
plt.show()
print(training_labels[index])

from sklearn.metrics import confusion_matrix
import itertools

plt.rcParams['figure.figsize'] = [60,30]

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):

  if normalize:
      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
      print("Normalized confusion matrix")
  else:
      print('Confusion matrix, without normalization')

  print(cm)

  plt.imshow(cm, interpolation='nearest', cmap=cmap)
  plt.title(title)
  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks, classes, rotation=45)
  plt.yticks(tick_marks, classes)

  fmt = '.2f' if normalize else 'd'
  thresh = cm.max() / 2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
      plt.text(j, i, format(cm[i, j], fmt),
               horizontalalignment="center",
               color="white" if cm[i, j] > thresh else "black")

  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()


p_test = cnn_model.predict(training_images).argmax(axis=1)
cm = confusion_matrix(training_labels, p_test)
plot_confusion_matrix(cm, list(range(10)))

plt.rcParams['figure.figsize'] = [10,5]
plt.plot(history.history['loss'], label='loss')